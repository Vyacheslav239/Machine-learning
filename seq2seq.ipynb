{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E79byEVWg5Im"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkE78bpduLUV"
      },
      "source": [
        "# seq2seq\n",
        "Замысел предложен в работе [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzdXz1E4g5Iq"
      },
      "source": [
        "В чистом виде seq2seq \"через\" один thought vector не особо работает, поэтому мы ещё добавим механизм внимания.\n",
        "\n",
        "Он, в свою очередь, был добавлен в эту модель в работе [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473).\n",
        "\n",
        "Другие полезные статьи:\n",
        "\n",
        "* [Learning Phrase Representations using RNN Encoder-Decoder for\n",
        "   Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n",
        "* [Sequence to Sequence Learning with Neural\n",
        "   Networks](https://arxiv.org/abs/1409.3215)\n",
        "* [Neural Machine Translation by Jointly Learning to Align and\n",
        "   Translate](https://arxiv.org/abs/1409.0473)\n",
        "* [A Neural Conversational Model](https://arxiv.org/abs/1506.05869)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIve9Hbdg5It",
        "outputId": "244d02b2-252e-4506-c3ed-edd49c9c6848"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjvxlIRLQ4uH"
      },
      "outputs": [],
      "source": [
        "random.seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrlkZ5xsx3b3"
      },
      "source": [
        "Как и во всякой не самой тривиальной постановке задачи, тут будет много вспомогательного кода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNKIk5I_g5Iu"
      },
      "source": [
        "## Загрузка\n",
        "Занружаем наш датасет\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "5VG2HV7tyOx-",
        "outputId": "351e924b-46f5-4f81-ebe6-ff6319e34aa9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>SPORTSWRITER</td>\n",
              "      <td>S P AO1 R T S R AY2 T ER0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>SKINS</td>\n",
              "      <td>S K IH1 N Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ACHEY</td>\n",
              "      <td>AE1 CH IY0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>SPINNER</td>\n",
              "      <td>S P IH1 N ER0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>REALLOCATION</td>\n",
              "      <td>R IY0 AE2 L AH0 K EY1 SH AH0 N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65935</th>\n",
              "      <td>65935</td>\n",
              "      <td>MERCS</td>\n",
              "      <td>M ER1 K S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65936</th>\n",
              "      <td>65936</td>\n",
              "      <td>URGE</td>\n",
              "      <td>ER1 JH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65937</th>\n",
              "      <td>65937</td>\n",
              "      <td>MOHAWK</td>\n",
              "      <td>M OW1 HH AO2 K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65938</th>\n",
              "      <td>65938</td>\n",
              "      <td>BALTAZAR</td>\n",
              "      <td>B AA0 L T AA0 Z AA1 R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65939</th>\n",
              "      <td>65939</td>\n",
              "      <td>YACHTE</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65940 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id           src                             tgt\n",
              "0          0  SPORTSWRITER       S P AO1 R T S R AY2 T ER0\n",
              "1          1         SKINS                     S K IH1 N Z\n",
              "2          2         ACHEY                      AE1 CH IY0\n",
              "3          3       SPINNER                   S P IH1 N ER0\n",
              "4          4  REALLOCATION  R IY0 AE2 L AH0 K EY1 SH AH0 N\n",
              "...      ...           ...                             ...\n",
              "65935  65935         MERCS                       M ER1 K S\n",
              "65936  65936          URGE                          ER1 JH\n",
              "65937  65937        MOHAWK                  M OW1 HH AO2 K\n",
              "65938  65938      BALTAZAR           B AA0 L T AA0 Z AA1 R\n",
              "65939  65939        YACHTE                             NaN\n",
              "\n",
              "[65940 rows x 3 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prepare data\n",
        "\n",
        "MAX_LENGTH = 60\n",
        "df = pd.read_csv('train.tsv', sep='\\t')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYr5SWZ8Q_x3",
        "outputId": "34e68b03-0b2e-407a-a341-0fe69617abd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soZHiXcJpIho"
      },
      "outputs": [],
      "source": [
        "with open('input.txt', 'w') as out_file:\n",
        "  for x in np.array(df):\n",
        "    # print(str(x[2]) + '\\t' + str(x[1]) + '\\n')\n",
        "    out_file.write(str(x[2]) + '\\t' + str(x[1]) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f30vURvCg5Iv"
      },
      "source": [
        "one-hot-encod-им каждое слово, при этом обрежем словарь по частотам, чтобы размерность была не километровая."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZwM6TAJg5Iv"
      },
      "source": [
        "Как и раньше, пронумеруем слова, и заодно посчитаем количество вхождений -- чтобы потом обрезать словарь по частоте."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npCJf7oSg5Iw"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "  \n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index, self.word2count = {}, {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Учитываем SOS и EOS, это счётчик для нумерации\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5QHJEcgg5Ix"
      },
      "source": [
        "Нормализуем тексты -- приведём к ASCII, приведём в нижний регистр.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2vZJVLLg5Ix"
      },
      "outputs": [],
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h68x2WRVPb7"
      },
      "outputs": [],
      "source": [
        "def read_langs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    lines = open('input.txt', encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # бьём по табу и нормализовываем ТУДУ\n",
        "    pairs = [[normalizeString(l.split('\\t')[0]), ' '.join(l.split('\\t')[1].lower().strip())] for l in lines]\n",
        "    print(pairs[:5])\n",
        "    # создаём объекты класса Lang\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4MjVJBag5I0"
      },
      "source": [
        "Теперь соберём все наши функции-заготовки в пайплайн подготовки текстов к подаче модели на вход"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPrNDUnQg5I1",
        "outputId": "37ca98c3-e48f-4f2a-b14f-e69b33a377d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "[['s p ao1 r t s r ay2 t er0', 's p o r t s w r i t e r'], ['s k ih1 n z', 's k i n s'], ['ae1 ch iy0', 'a c h e y'], ['s p ih1 n er0', 's p i n n e r'], ['r iy0 ae2 l ah0 k ey1 sh ah0 n', 'r e a l l o c a t i o n']]\n",
            "Read 65940 sentence pairs\n",
            "Trimmed to 65940 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "phn 30\n",
            "wrd 72\n",
            "['p e a r s e', 'p er1 s']\n"
          ]
        }
      ],
      "source": [
        "def prepare_data(lang1, lang2, reverse=False):\n",
        "\n",
        "    input_lang, output_lang, pairs = read_langs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.add_sentence(pair[0])\n",
        "        output_lang.add_sentence(pair[1])\n",
        "\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepare_data('wrd', 'phn', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bMFaDlOg5I1"
      },
      "source": [
        "## Собственно модель\n",
        "\n",
        "В стандартной постановке мы проходим по входной последовательности рекуррентной сетью, и на выходе получаем thought vector, из которого авторегрессивно декодируем последовательность вообще говоря другой длины.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEBT1H-ag5I2"
      },
      "source": [
        "Кодировщик (Encoder)\n",
        "-----------\n",
        "Обычная такая RNN-ка, которая использует входную последовательность и предыдущее состояние.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_kgP-0Yg5I2"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbxQNIVdOxSi"
      },
      "source": [
        "Как видите, ничего нового."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGZXALg9g5I2"
      },
      "source": [
        "Декодировщик (Decoder)\n",
        "-----------\n",
        "\n",
        "Берёт вектор(ы) кодировщика и порождает последовательность.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPK0et3ug5I3"
      },
      "source": [
        "### Декодировщик с механизмом внимания\n",
        "\n",
        "Смотрим на выходы кодировщика и дополняем их взвешенной обучаемой комбинацией информацию (фичи) на каждом шаге декодировщика (см. ``attn_applied``).\n",
        "\n",
        "Вычисление весов внимания делается полносвязным слоем ``attn`` которому на вход подаются (а) вход декодера, (б) скрытое состояние декодера. То есть так мы подбираем вес, учитывая и декодируемую последовательность и конкретный \"предыдущий токен\".\n",
        "\n",
        "Но при этом нам всё-таки придётся ограничить возможную длину последовательности.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuBmnIT0g5I4"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "\n",
        "        self.hidden_size, self.output_size = hidden_size, output_size\n",
        "        self.dropout_p, self.max_length = dropout_p, max_length\n",
        "\n",
        "        # преобразовываем вход\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "\n",
        "        # у внимания \"двойной\" вход, а выход -- \n",
        "        # набор скаляров на всю потенциальную длину КОДИРУЕМОГО предложения\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "\n",
        "        # будем объединять взвешенную сумму выходов кодировщика \n",
        "        # и эмбеддинг в один вектор на вход для ячейки GRU \n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "\n",
        "        # предсказания\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "\n",
        "        # построили эмбеддинг\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        # применили дропаут\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        # применили линейный слой к преобразованному входу и полученному \n",
        "        # скрытому состоянию; получили вектор длины max_length\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        \n",
        "        # домножили выходы кодировщика на веса внимания\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        # приклеили полученный вектор к эмбеддингу входа\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        # применили нелинейное преобразование\n",
        "        output = F.relu(output)\n",
        "\n",
        "        # применили рекуррентную ячейку\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        # применили к выходу софтмакс, чтобы получить очередной токен\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        \n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q259ietg5I4"
      },
      "source": [
        "Как мы уже обсудил, это не единственный вариант внимания, можно использовать и более \"удачные\" в вычислительном плане подходы, например, [Effective Approaches to Attention-based Neural Machine](https://arxiv.org/abs/1508.04025)\n",
        "\n",
        "## Обучение\n",
        "\n",
        "Подготовка данных: превращаем тексты в тензоры, не забывая прикреплять SOS/EOS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdQrUtfzg5I4"
      },
      "outputs": [],
      "source": [
        "def indexes_from_sentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensor_from_sentence(lang, sentence):\n",
        "    indexes = indexes_from_sentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensor_from_pair(pair):\n",
        "    input_tensor = tensor_from_sentence(input_lang, pair[0])\n",
        "    target_tensor = tensor_from_sentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnrZ3vepg5I5"
      },
      "source": [
        "### Собственно обучение\n",
        "\n",
        "Есть разные подходы, как правильно обучать.\n",
        "\n",
        "\"Teacher forcing\" -- подавать на вход декодировщику ПРАВИЛЬНЫЕ, а не предсказанные моделью на этом этапе токены. Сходится быстрее, но когда дело доходит до практики, результаты [очень нестабильные](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf).\n",
        "\n",
        "Таким образом обученная модель генерирует часто грамматически корректные предложения, которые имеют мало общего со смыслом исходного текста.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArGI4EiFg5I5"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, \n",
        "          encoder, decoder, \n",
        "          encoder_optimizer, decoder_optimizer, # да, два\n",
        "          criterion, max_length=MAX_LENGTH):\n",
        "  \n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0) # первое измерение -- длина\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # True, если меньше выбранной \"доли срабатываний\" `teacher_forcing_ratio`\n",
        "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: подставляем истинный токен на всей последовательности\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, # индекс\n",
        "                decoder_hidden, # скрытое состояния\n",
        "                encoder_outputs # выходы кодировщика\n",
        "                )\n",
        "            # сравниваем выход декодировщика с ИСТИННЫМ тензором (это всегда)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            # берём в качестве следующего входа ИСТИННЫЙ тензор --\n",
        "            decoder_input = target_tensor[di]  # ... это teacher forcing\n",
        "\n",
        "    else:\n",
        "        # БЕЗ teacher forcing: собственные предсказания как сл. вход\n",
        "        for di in range(target_length):\n",
        "\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            \n",
        "            # берём самый большой выход софтмакса\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # открепляем от выч. графа\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "\n",
        "            # если предсказали EOS, заканчиваем\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW-OlX69g5I5"
      },
      "source": [
        "Вспомогательные функции, чтобы отслеживать, как далеко мы продвинулись и сколько времени прошло."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEBqPeOBg5I6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cby_3c_yg5I6"
      },
      "source": [
        "* Запускаем таймер,\n",
        "* задаём оптимизаторы и функцию потерь,\n",
        "* создаём набор данных для обучения,\n",
        "* сохраняем лоссы, чтобы отслеживать, как у нас идут дела, в картинках.\n",
        "\n",
        "Обучаем на случайных семплах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0TIPs2Og5I6"
      },
      "outputs": [],
      "source": [
        "def train_iter(encoder, decoder, \n",
        "               print_every=1000, plot_every=100, \n",
        "               learning_rate=0.01):\n",
        "    \n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total, plot_loss_total = 0, 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    training_pairs = [tensor_from_pair(pair)\n",
        "                      for pair in pairs]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, len(training_pairs) + 1):\n",
        "    # for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, \n",
        "                     encoder, decoder, \n",
        "                     encoder_optimizer, decoder_optimizer, \n",
        "                     criterion)\n",
        "        \n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / len(training_pairs)),\n",
        "                                         iter, iter / len(training_pairs) * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            # сохраняем средний лосс с прошлого момента измерения\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    show_plot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnkolegQg5I7"
      },
      "source": [
        "### Графики\n",
        "\n",
        "Строим, как меняется лосс во времени (``plot_losses``) в ходе обучения.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnG53NOXg5I7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def show_plot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    \n",
        "    # эта штука метки на осях расставляет\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnU_f8M9g5I7"
      },
      "source": [
        "## Оценка качества\n",
        "\n",
        "Примерно то же, что обучение, но, понятно, без teacher forcing. То есть  -- что декодер предсказал на этом шаге, то и подали ему как вход на следующий.\n",
        "\n",
        "Для анализа впоследствии мы также сохраняем значения внимания.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riHwGVRgg5I8"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        input_tensor = tensor_from_sentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # сохраняем для последующего анализа\n",
        "        decoded_words = [] \n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "            # раз            \n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                # два\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9juG5IsUg5I8"
      },
      "source": [
        "Можно просто глазами посмотреть на поведение на отдельных случайных парах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC0ms2sSg5I8"
      },
      "outputs": [],
      "source": [
        "def evaluate_randomly(encoder, decoder, n=10):\n",
        "    \n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyZzllNig5I8"
      },
      "source": [
        "## Обучение и оценка\n",
        "\n",
        "Не забывайте, что датасет игрушечный, на нормальном всё так хорошо работать не будет.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "80sqqQ46g5I9",
        "outputId": "1596aeb2-7a2b-4d8e-a2a2-bcf47331f4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "1m 31s (- 8m 29s) (10000 15%) 2.4774\n",
            "3m 10s (- 7m 16s) (20000 30%) 2.6502\n",
            "4m 55s (- 5m 53s) (30000 45%) 2.8873\n",
            "6m 42s (- 4m 21s) (40000 60%) 2.9766\n",
            "8m 30s (- 2m 42s) (50000 75%) 2.9321\n",
            "10m 17s (- 1m 1s) (60000 90%) 2.9140\n",
            "epoch 2\n",
            "1m 48s (- 10m 6s) (10000 15%) 2.9190\n",
            "3m 36s (- 8m 16s) (20000 30%) 2.8998\n",
            "5m 22s (- 6m 26s) (30000 45%) 2.8616\n",
            "7m 9s (- 4m 38s) (40000 60%) 2.8332\n",
            "8m 56s (- 2m 51s) (50000 75%) 2.8267\n",
            "10m 43s (- 1m 3s) (60000 90%) 2.8230\n",
            "epoch 3\n",
            "1m 50s (- 10m 17s) (10000 15%) 2.8145\n",
            "3m 38s (- 8m 21s) (20000 30%) 2.8167\n",
            "5m 27s (- 6m 32s) (30000 45%) 2.8113\n",
            "7m 16s (- 4m 43s) (40000 60%) 2.7899\n",
            "9m 5s (- 2m 53s) (50000 75%) 2.7768\n",
            "10m 55s (- 1m 4s) (60000 90%) 2.7699\n",
            "epoch 4\n",
            "1m 52s (- 10m 30s) (10000 15%) 2.7398\n",
            "3m 46s (- 8m 39s) (20000 30%) 2.7194\n",
            "5m 38s (- 6m 46s) (30000 45%) 2.6946\n",
            "7m 31s (- 4m 52s) (40000 60%) 2.6580\n",
            "9m 24s (- 2m 59s) (50000 75%) 2.6285\n",
            "11m 18s (- 1m 7s) (60000 90%) 2.5975\n",
            "epoch 5\n",
            "1m 53s (- 10m 36s) (10000 15%) 2.5445\n",
            "3m 46s (- 8m 41s) (20000 30%) 2.5048\n",
            "5m 40s (- 6m 47s) (30000 45%) 2.4722\n",
            "7m 34s (- 4m 54s) (40000 60%) 2.4260\n",
            "9m 29s (- 3m 1s) (50000 75%) 2.3948\n",
            "11m 21s (- 1m 7s) (60000 90%) 2.3701\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "lr = [0.005, 0.003, 0.002, 0.001, 0.001, 0.0009, 0.0008, 0.0007, 0.0006, 0.0005]\n",
        "epochs = 10\n",
        "for i in range(epochs):\n",
        "  print('epoch {}'.format(i + 1))\n",
        "  train_iter(encoder1, attn_decoder1, print_every=10000, learning_rate = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKDB-AuEg5I9"
      },
      "outputs": [],
      "source": [
        "evaluate_randomly(encoder1, attn_decoder1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91Sbp7nCzRKY"
      },
      "source": [
        "# Вывод"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uhf5IdacwQaq"
      },
      "outputs": [],
      "source": [
        "def write_solution(encoder, decoder):\n",
        "  outs = []\n",
        "  df = pd.read_csv('test2.tsv', sep='\\t')\n",
        "  out_df = pd.DataFrame(columns=['id', 'tgt']).reset_index(drop=True)\n",
        "  for i in np.array(df):\n",
        "    word = ' '.join(i[1]).lower().strip()\n",
        "    output_words, attentions = evaluate(encoder, decoder, word)\n",
        "    output_sentence = ' '.join(output_words)[:-6]\n",
        "    out_df = out_df.append({'id': i[0], 'tgt': output_sentence.upper().strip()}, ignore_index=True)\n",
        "  out_df = out_df.set_index('id')\n",
        "  out_df.to_csv('submission.csv')\n",
        "  return out_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxc0XLYA0Wwk"
      },
      "outputs": [],
      "source": [
        "out = write_solution(encoder1, attn_decoder1)\n",
        "out.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPS9AFdx41ok"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Last_hw_sidelnik.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}